{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8670</td>\n",
       "      <td>M</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8913</td>\n",
       "      <td>B</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>B</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9047</td>\n",
       "      <td>B</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85715</td>\n",
       "      <td>M</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0   8670         M        15.46         19.48          101.70      748.9   \n",
       "1   8913         B        12.89         13.12           81.89      515.9   \n",
       "2   8915         B        14.96         19.10           97.03      687.3   \n",
       "3   9047         B        12.94         16.17           83.18      507.6   \n",
       "4  85715         M        13.17         18.66           85.98      534.6   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.10920           0.12230         0.14660              0.08087   \n",
       "1          0.06955           0.03729         0.02260              0.01171   \n",
       "2          0.08992           0.09823         0.05940              0.04819   \n",
       "3          0.09879           0.08836         0.03296              0.02390   \n",
       "4          0.11580           0.12310         0.12260              0.07340   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         19.26          26.00           124.90      1156.0   \n",
       "1  ...         13.62          15.54            87.40       577.0   \n",
       "2  ...         16.25          26.19           109.10       809.8   \n",
       "3  ...         13.86          23.02            89.69       580.9   \n",
       "4  ...         15.67          27.95           102.80       759.4   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0           0.15460             0.2394           0.3791               0.15140   \n",
       "1           0.09616             0.1147           0.1186               0.05366   \n",
       "2           0.13130             0.3030           0.1804               0.14890   \n",
       "3           0.11720             0.1958           0.1810               0.08388   \n",
       "4           0.17860             0.4166           0.5006               0.20880   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.2837                  0.08019  \n",
       "1          0.2309                  0.06915  \n",
       "2          0.2962                  0.08472  \n",
       "3          0.3297                  0.07834  \n",
       "4          0.3900                  0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df = pd.read_csv(os.path.join(\"data.csv\"))\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.loc[(cancer_df.diagnosis == 'B'),'diagnosis']='Benign'\n",
    "cancer_df.loc[(cancer_df.diagnosis == 'M'),'diagnosis']='Malignant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.rename(columns = {'id':'Paitent ID', 'diagnosis':'Diagnosis'\n",
    "                            , 'radius_mean':'Radius (Mean)', 'texture_mean':'Texture (Mean)', 'perimeter_mean':'Perimeter (Mean)'\n",
    "                           , 'area_mean':'Area (Mean)', 'smoothness_mean':'Smoothness (Mean)', 'compactness_mean':'Compactness (Mean)', 'concavity_mean':'Concavity (Mean)', 'concave points_mean':'Concave Points (Mean)'\n",
    "                           , 'symmetry_mean':'Symmetry (Mean)', 'fractal_dimension_mean':'Fractal Dimension (Mean)'\n",
    "                            , 'radius_se':'Radius (Standard Error)', 'texture_se':'Texture (Standard Error)', 'perimeter_se':'Perimeter (Standard Error)'\n",
    "                            , 'area_se':'Area (Standard Error)', 'smoothness_se':'Smoothness (Standard Error)', 'compactness_se':'Compactness (Standard Error)', 'concavity_se':'Concavity (Standard Error)', 'concave points_se':'Concave Points (Standard Error)'\n",
    "                            , 'symmetry_se':'Symmetry (Standard Error)', 'fractal_dimension_se':'Fractal Dimension (Standard Error)'\n",
    "                            , 'radius_worst':'Radius (Worst)', 'texture_worst':'Texture (Worst)', 'perimeter_worst':'Perimeter (Worst)'\n",
    "                           , 'area_worst':'Area (Worst)', 'smoothness_worst':'Smoothness (Worst)', 'compactness_worst':'Compactness (Worst)', 'concavity_worst':'Concavity (Worst)', 'concave points_worst':'Concave Points (Worst)'\n",
    "                           , 'symmetry_worst':'Symmetry (Worst)', 'fractal_dimension_worst':'Fractal Dimension (Worst)'\n",
    "                           }, inplace = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.to_csv(r\"C:\\Users\\Magrathea\\Documents\\GIT_Hub\\Projects\\Final-Project\\Cancer_Data.csv\")\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31) (569,)\n"
     ]
    }
   ],
   "source": [
    "X = cancer_df.drop(\"Diagnosis\", axis=1)\n",
    "y = cancer_df[\"Diagnosis\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Magrathea\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.40375586854460094\n",
      "Testing Data Score: 0.44755244755244755\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   ['Malignant' 'Malignant' 'Malignant' 'Malignant' 'Malignant' 'Malignant'\n",
      " 'Malignant' 'Malignant' 'Malignant' 'Malignant']\n",
      "First 10 Actual labels: ['Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign']\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction     Actual\n",
       "0    Malignant  Malignant\n",
       "1    Malignant  Malignant\n",
       "2    Malignant     Benign\n",
       "3       Benign     Benign\n",
       "4    Malignant     Benign\n",
       "..         ...        ...\n",
       "138     Benign  Malignant\n",
       "139  Malignant     Benign\n",
       "140  Malignant     Benign\n",
       "141  Malignant     Benign\n",
       "142  Malignant     Benign\n",
       "\n",
       "[143 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cancer_df[\"Diagnosis\"]\n",
    "target_names = [\"negative\", \"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>Symmetry (Mean)</th>\n",
       "      <th>Fractal Dimension (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.05796</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.05852</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.06200</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.06777</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Radius (Mean)  Texture (Mean)  Perimeter (Mean)  Area (Mean)  \\\n",
       "0          15.46           19.48            101.70        748.9   \n",
       "1          12.89           13.12             81.89        515.9   \n",
       "2          14.96           19.10             97.03        687.3   \n",
       "3          12.94           16.17             83.18        507.6   \n",
       "4          13.17           18.66             85.98        534.6   \n",
       "\n",
       "   Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0            0.10920             0.12230           0.14660   \n",
       "1            0.06955             0.03729           0.02260   \n",
       "2            0.08992             0.09823           0.05940   \n",
       "3            0.09879             0.08836           0.03296   \n",
       "4            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  Symmetry (Mean)  Fractal Dimension (Mean)  ...  \\\n",
       "0                0.08087           0.1931                   0.05796  ...   \n",
       "1                0.01171           0.1337                   0.05581  ...   \n",
       "2                0.04819           0.1879                   0.05852  ...   \n",
       "3                0.02390           0.1735                   0.06200  ...   \n",
       "4                0.07340           0.2128                   0.06777  ...   \n",
       "\n",
       "   Radius (Worst)  Texture (Worst)  Perimeter (Worst)  Area (Worst)  \\\n",
       "0           19.26            26.00             124.90        1156.0   \n",
       "1           13.62            15.54              87.40         577.0   \n",
       "2           16.25            26.19             109.10         809.8   \n",
       "3           13.86            23.02              89.69         580.9   \n",
       "4           15.67            27.95             102.80         759.4   \n",
       "\n",
       "   Smoothness (Worst)  Compactness (Worst)  Concavity (Worst)  \\\n",
       "0             0.15460               0.2394             0.3791   \n",
       "1             0.09616               0.1147             0.1186   \n",
       "2             0.13130               0.3030             0.1804   \n",
       "3             0.11720               0.1958             0.1810   \n",
       "4             0.17860               0.4166             0.5006   \n",
       "\n",
       "   Concave Points (Worst)  Symmetry (Worst)  Fractal Dimension (Worst)  \n",
       "0                 0.15140            0.2837                    0.08019  \n",
       "1                 0.05366            0.2309                    0.06915  \n",
       "2                 0.14890            0.2962                    0.08472  \n",
       "3                 0.08388            0.3297                    0.07834  \n",
       "4                 0.20880            0.3900                    0.11790  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = cancer_df.drop(\"Diagnosis\", axis =1)\n",
    "X = X_df.drop(\"Paitent ID\", axis =1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.916\n",
      "k: 3, Train/Test Score: 0.958/0.923\n",
      "k: 5, Train/Test Score: 0.944/0.930\n",
      "k: 7, Train/Test Score: 0.944/0.916\n",
      "k: 9, Train/Test Score: 0.944/0.916\n",
      "k: 11, Train/Test Score: 0.946/0.923\n",
      "k: 13, Train/Test Score: 0.944/0.923\n",
      "k: 15, Train/Test Score: 0.937/0.930\n",
      "k: 17, Train/Test Score: 0.937/0.930\n",
      "k: 19, Train/Test Score: 0.937/0.930\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=13 Test Acc: 0.923\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(X_train, y_train)\n",
    "print('k=13 Test Acc: %.3f' % knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_test)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Step 2: One-hot encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9020979020979021"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train_categorical)\n",
    "clf.score(X_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.916083916083916"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train_categorical)\n",
    "rf.score(X_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.17364912937963653, 'Perimeter (Worst)'),\n",
       " (0.12198895784852827, 'Area (Worst)'),\n",
       " (0.11472964884800935, 'Concave Points (Worst)'),\n",
       " (0.10791822877720775, 'Radius (Worst)'),\n",
       " (0.08188362944791223, 'Concave Points (Mean)'),\n",
       " (0.06047526314303535, 'Concavity (Mean)'),\n",
       " (0.056725388774698814, 'Area (Mean)'),\n",
       " (0.04216071328748826, 'Perimeter (Mean)'),\n",
       " (0.041721200376517484, 'Area (Standard Error)'),\n",
       " (0.03915986596794634, 'Radius (Mean)'),\n",
       " (0.025436624677379446, 'Concavity (Worst)'),\n",
       " (0.019712429268053028, 'Radius (Standard Error)'),\n",
       " (0.017587447384719825, 'Compactness (Worst)'),\n",
       " (0.010329549281632773, 'Compactness (Mean)'),\n",
       " (0.010072685348864421, 'Symmetry (Worst)'),\n",
       " (0.009547168208132844, 'Texture (Worst)'),\n",
       " (0.009261714575672403, 'Texture (Mean)'),\n",
       " (0.007787629746063619, 'Smoothness (Worst)'),\n",
       " (0.007331423803633955, 'Fractal Dimension (Worst)'),\n",
       " (0.007113289494008737, 'Perimeter (Standard Error)'),\n",
       " (0.005262875335990815, 'Texture (Standard Error)'),\n",
       " (0.004476584358844042, 'Smoothness (Mean)'),\n",
       " (0.004391771163758686, 'Symmetry (Mean)'),\n",
       " (0.004122237389065074, 'Fractal Dimension (Mean)'),\n",
       " (0.004082451967470807, 'Concavity (Standard Error)'),\n",
       " (0.0033153117550420884, 'Concave Points (Standard Error)'),\n",
       " (0.003048603979647843, 'Symmetry (Standard Error)'),\n",
       " (0.0024269986859066996, 'Smoothness (Standard Error)'),\n",
       " (0.002306542583775502, 'Compactness (Standard Error)'),\n",
       " (0.001974635141356768, 'Fractal Dimension (Standard Error)')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = cancer_df[\"Diagnosis\"]\n",
    "target_names = [\"negative\", \"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>Symmetry (Mean)</th>\n",
       "      <th>Fractal Dimension (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.05796</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.05852</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.06200</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.06777</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Radius (Mean)  Texture (Mean)  Perimeter (Mean)  Area (Mean)  \\\n",
       "0          15.46           19.48            101.70        748.9   \n",
       "1          12.89           13.12             81.89        515.9   \n",
       "2          14.96           19.10             97.03        687.3   \n",
       "3          12.94           16.17             83.18        507.6   \n",
       "4          13.17           18.66             85.98        534.6   \n",
       "\n",
       "   Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0            0.10920             0.12230           0.14660   \n",
       "1            0.06955             0.03729           0.02260   \n",
       "2            0.08992             0.09823           0.05940   \n",
       "3            0.09879             0.08836           0.03296   \n",
       "4            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  Symmetry (Mean)  Fractal Dimension (Mean)  ...  \\\n",
       "0                0.08087           0.1931                   0.05796  ...   \n",
       "1                0.01171           0.1337                   0.05581  ...   \n",
       "2                0.04819           0.1879                   0.05852  ...   \n",
       "3                0.02390           0.1735                   0.06200  ...   \n",
       "4                0.07340           0.2128                   0.06777  ...   \n",
       "\n",
       "   Radius (Worst)  Texture (Worst)  Perimeter (Worst)  Area (Worst)  \\\n",
       "0           19.26            26.00             124.90        1156.0   \n",
       "1           13.62            15.54              87.40         577.0   \n",
       "2           16.25            26.19             109.10         809.8   \n",
       "3           13.86            23.02              89.69         580.9   \n",
       "4           15.67            27.95             102.80         759.4   \n",
       "\n",
       "   Smoothness (Worst)  Compactness (Worst)  Concavity (Worst)  \\\n",
       "0             0.15460               0.2394             0.3791   \n",
       "1             0.09616               0.1147             0.1186   \n",
       "2             0.13130               0.3030             0.1804   \n",
       "3             0.11720               0.1958             0.1810   \n",
       "4             0.17860               0.4166             0.5006   \n",
       "\n",
       "   Concave Points (Worst)  Symmetry (Worst)  Fractal Dimension (Worst)  \n",
       "0                 0.15140            0.2837                    0.08019  \n",
       "1                 0.05366            0.2309                    0.06915  \n",
       "2                 0.14890            0.2962                    0.08472  \n",
       "3                 0.08388            0.3297                    0.07834  \n",
       "4                 0.20880            0.3900                    0.11790  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = cancer_df.drop(\"Diagnosis\", axis =1)\n",
    "data = data_1.drop(\"Paitent ID\", axis =1)\n",
    "feature_names = data.columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support vector machine linear classifier\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.972\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy\n",
    "print('Test Acc: %.3f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      1.00      0.98        80\n",
      "    positive       1.00      0.94      0.97        63\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.98      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machine linear classifier\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "              'gamma': [0.0001, 0.001, 0.01]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Magrathea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.923, total=   0.4s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.937, total=   0.7s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.943, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.923, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.937, total=   0.7s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.943, total=   0.4s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.923, total=   0.4s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.937, total=   0.7s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.943, total=   0.4s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.916, total=   0.7s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.937, total=   1.5s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.929, total=   4.5s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.916, total=   0.7s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.937, total=   1.7s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.929, total=   4.5s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.916, total=   0.7s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.937, total=   1.7s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.929, total=   4.6s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.930, total=   0.7s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.937, total=   2.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.943, total=   2.5s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.930, total=   0.7s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.937, total=   2.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.943, total=   2.6s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.930, total=   0.7s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.937, total=   2.2s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.943, total=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   41.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='linear',\n",
       "                           max_iter=-1, probability=False, random_state=None,\n",
       "                           shrinking=True, tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using the grid search estimator. \n",
    "# This will take the SVC model and try each combination of parameters\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9366197183098591\n"
     ]
    }
   ],
   "source": [
    "# List the best score\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        blue       0.96      1.00      0.98        80\n",
      "         red       1.00      0.95      0.98        63\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"blue\", \"red\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Reformat data\n",
    "data = cancer_df.values\n",
    "X = data[:, 2:35]\n",
    "y = data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_test)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Step 2: One-hot encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "number_inputs = 30\n",
    "number_hidden_nodes = 4\n",
    "model.add(Dense(units=number_hidden_nodes,\n",
    "                activation='relu', input_dim=number_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = 2\n",
    "model.add(Dense(units=6, activation='relu', input_dim=2))\n",
    "model.add(Dense(units=6, activation='relu'))\n",
    "model.add(Dense(units=number_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 4)                 124       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 18        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 134\n",
      "Trainable params: 134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "# Hint: your output layer in this example is using software for logistic regression (categorical)\n",
    "# If your output layer activation was `linear` then you may want to use `mse` for loss\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(426, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(y_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples\n",
      "Epoch 1/1000\n",
      "426/426 - 0s - loss: 0.6837 - accuracy: 0.6432\n",
      "Epoch 2/1000\n",
      "426/426 - 0s - loss: 0.6621 - accuracy: 0.6432\n",
      "Epoch 3/1000\n",
      "426/426 - 0s - loss: 0.6411 - accuracy: 0.6432\n",
      "Epoch 4/1000\n",
      "426/426 - 0s - loss: 0.6191 - accuracy: 0.6432\n",
      "Epoch 5/1000\n",
      "426/426 - 0s - loss: 0.5955 - accuracy: 0.6432\n",
      "Epoch 6/1000\n",
      "426/426 - 0s - loss: 0.5700 - accuracy: 0.6432\n",
      "Epoch 7/1000\n",
      "426/426 - 0s - loss: 0.5438 - accuracy: 0.6432\n",
      "Epoch 8/1000\n",
      "426/426 - 0s - loss: 0.5156 - accuracy: 0.8216\n",
      "Epoch 9/1000\n",
      "426/426 - 0s - loss: 0.4852 - accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "426/426 - 0s - loss: 0.4530 - accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "426/426 - 0s - loss: 0.4192 - accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "426/426 - 0s - loss: 0.3843 - accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "426/426 - 0s - loss: 0.3487 - accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "426/426 - 0s - loss: 0.3132 - accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "426/426 - 0s - loss: 0.2784 - accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "426/426 - 0s - loss: 0.2452 - accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "426/426 - 0s - loss: 0.2143 - accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "426/426 - 0s - loss: 0.1861 - accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "426/426 - 0s - loss: 0.1606 - accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "426/426 - 0s - loss: 0.1389 - accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "426/426 - 0s - loss: 0.1208 - accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "426/426 - 0s - loss: 0.1051 - accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "426/426 - 0s - loss: 0.0918 - accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "426/426 - 0s - loss: 0.0804 - accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "426/426 - 0s - loss: 0.0706 - accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "426/426 - 0s - loss: 0.0624 - accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "426/426 - 0s - loss: 0.0552 - accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "426/426 - 0s - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "426/426 - 0s - loss: 0.0440 - accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "426/426 - 0s - loss: 0.0395 - accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "426/426 - 0s - loss: 0.0356 - accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "426/426 - 0s - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "426/426 - 0s - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "426/426 - 0s - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "426/426 - 0s - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "426/426 - 0s - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "426/426 - 0s - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "426/426 - 0s - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "426/426 - 0s - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "426/426 - 0s - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "426/426 - 0s - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "426/426 - 0s - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "426/426 - 0s - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "426/426 - 0s - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "426/426 - 0s - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "426/426 - 0s - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "426/426 - 0s - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "426/426 - 0s - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "426/426 - 0s - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "426/426 - 0s - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "426/426 - 0s - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "426/426 - 0s - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "426/426 - 0s - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "426/426 - 0s - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "426/426 - 0s - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "426/426 - 0s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "426/426 - 0s - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "426/426 - 0s - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "426/426 - 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "426/426 - 0s - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "426/426 - 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "426/426 - 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "426/426 - 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "426/426 - 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "426/426 - 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "426/426 - 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "426/426 - 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "426/426 - 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "426/426 - 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "426/426 - 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "426/426 - 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "426/426 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "426/426 - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "426/426 - 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "426/426 - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "426/426 - 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "426/426 - 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "426/426 - 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "426/426 - 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "426/426 - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "426/426 - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "426/426 - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "426/426 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "426/426 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "426/426 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "426/426 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "426/426 - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "426/426 - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "426/426 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "426/426 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "426/426 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "426/426 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "426/426 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "426/426 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "426/426 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "426/426 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "426/426 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "426/426 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "426/426 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "426/426 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "426/426 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "426/426 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "426/426 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "426/426 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "426/426 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "426/426 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "426/426 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "426/426 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "426/426 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "426/426 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "426/426 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "426/426 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "426/426 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "426/426 - 0s - loss: 9.9398e-04 - accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "426/426 - 0s - loss: 9.7311e-04 - accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "426/426 - 0s - loss: 9.5313e-04 - accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "426/426 - 0s - loss: 9.3354e-04 - accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "426/426 - 0s - loss: 9.1447e-04 - accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "426/426 - 0s - loss: 8.9602e-04 - accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "426/426 - 0s - loss: 8.7789e-04 - accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "426/426 - 0s - loss: 8.6052e-04 - accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "426/426 - 0s - loss: 8.4340e-04 - accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "426/426 - 0s - loss: 8.2689e-04 - accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "426/426 - 0s - loss: 8.1086e-04 - accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "426/426 - 0s - loss: 7.9486e-04 - accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "426/426 - 0s - loss: 7.7958e-04 - accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "426/426 - 0s - loss: 7.6472e-04 - accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "426/426 - 0s - loss: 7.5018e-04 - accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "426/426 - 0s - loss: 7.3602e-04 - accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "426/426 - 0s - loss: 7.2233e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/1000\n",
      "426/426 - 0s - loss: 7.0894e-04 - accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "426/426 - 0s - loss: 6.9587e-04 - accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "426/426 - 0s - loss: 6.8309e-04 - accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "426/426 - 0s - loss: 6.7065e-04 - accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "426/426 - 0s - loss: 6.5863e-04 - accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "426/426 - 0s - loss: 6.4681e-04 - accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "426/426 - 0s - loss: 6.3545e-04 - accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "426/426 - 0s - loss: 6.2406e-04 - accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "426/426 - 0s - loss: 6.1318e-04 - accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "426/426 - 0s - loss: 6.0258e-04 - accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "426/426 - 0s - loss: 5.9214e-04 - accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "426/426 - 0s - loss: 5.8189e-04 - accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "426/426 - 0s - loss: 5.7195e-04 - accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "426/426 - 0s - loss: 5.6213e-04 - accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "426/426 - 0s - loss: 5.5267e-04 - accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "426/426 - 0s - loss: 5.4336e-04 - accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "426/426 - 0s - loss: 5.3426e-04 - accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "426/426 - 0s - loss: 5.2535e-04 - accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "426/426 - 0s - loss: 5.1667e-04 - accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "426/426 - 0s - loss: 5.0807e-04 - accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "426/426 - 0s - loss: 4.9975e-04 - accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "426/426 - 0s - loss: 4.9159e-04 - accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "426/426 - 0s - loss: 4.8364e-04 - accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "426/426 - 0s - loss: 4.7582e-04 - accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "426/426 - 0s - loss: 4.6822e-04 - accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "426/426 - 0s - loss: 4.6070e-04 - accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "426/426 - 0s - loss: 4.5333e-04 - accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "426/426 - 0s - loss: 4.4621e-04 - accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "426/426 - 0s - loss: 4.3915e-04 - accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "426/426 - 0s - loss: 4.3239e-04 - accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "426/426 - 0s - loss: 4.2566e-04 - accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "426/426 - 0s - loss: 4.1911e-04 - accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "426/426 - 0s - loss: 4.1263e-04 - accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "426/426 - 0s - loss: 4.0635e-04 - accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "426/426 - 0s - loss: 4.0017e-04 - accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "426/426 - 0s - loss: 3.9408e-04 - accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "426/426 - 0s - loss: 3.8824e-04 - accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "426/426 - 0s - loss: 3.8239e-04 - accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "426/426 - 0s - loss: 3.7662e-04 - accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "426/426 - 0s - loss: 3.7099e-04 - accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "426/426 - 0s - loss: 3.6549e-04 - accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "426/426 - 0s - loss: 3.6013e-04 - accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "426/426 - 0s - loss: 3.5486e-04 - accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "426/426 - 0s - loss: 3.4974e-04 - accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "426/426 - 0s - loss: 3.4459e-04 - accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "426/426 - 0s - loss: 3.3964e-04 - accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "426/426 - 0s - loss: 3.3474e-04 - accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "426/426 - 0s - loss: 3.2989e-04 - accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "426/426 - 0s - loss: 3.2518e-04 - accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "426/426 - 0s - loss: 3.2056e-04 - accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "426/426 - 0s - loss: 3.1601e-04 - accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "426/426 - 0s - loss: 3.1154e-04 - accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "426/426 - 0s - loss: 3.0716e-04 - accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "426/426 - 0s - loss: 3.0287e-04 - accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "426/426 - 0s - loss: 2.9863e-04 - accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "426/426 - 0s - loss: 2.9446e-04 - accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "426/426 - 0s - loss: 2.9044e-04 - accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "426/426 - 0s - loss: 2.8644e-04 - accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "426/426 - 0s - loss: 2.8248e-04 - accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "426/426 - 0s - loss: 2.7859e-04 - accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "426/426 - 0s - loss: 2.7477e-04 - accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "426/426 - 0s - loss: 2.7102e-04 - accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "426/426 - 0s - loss: 2.6738e-04 - accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "426/426 - 0s - loss: 2.6376e-04 - accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "426/426 - 0s - loss: 2.6017e-04 - accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "426/426 - 0s - loss: 2.5674e-04 - accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "426/426 - 0s - loss: 2.5331e-04 - accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "426/426 - 0s - loss: 2.4998e-04 - accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "426/426 - 0s - loss: 2.4667e-04 - accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "426/426 - 0s - loss: 2.4342e-04 - accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "426/426 - 0s - loss: 2.4021e-04 - accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "426/426 - 0s - loss: 2.3708e-04 - accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "426/426 - 0s - loss: 2.3401e-04 - accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "426/426 - 0s - loss: 2.3097e-04 - accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "426/426 - 0s - loss: 2.2801e-04 - accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "426/426 - 0s - loss: 2.2509e-04 - accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "426/426 - 0s - loss: 2.2218e-04 - accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "426/426 - 0s - loss: 2.1935e-04 - accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "426/426 - 0s - loss: 2.1655e-04 - accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "426/426 - 0s - loss: 2.1375e-04 - accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "426/426 - 0s - loss: 2.1104e-04 - accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "426/426 - 0s - loss: 2.0836e-04 - accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "426/426 - 0s - loss: 2.0570e-04 - accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "426/426 - 0s - loss: 2.0310e-04 - accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "426/426 - 0s - loss: 2.0057e-04 - accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "426/426 - 0s - loss: 1.9808e-04 - accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "426/426 - 0s - loss: 1.9561e-04 - accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "426/426 - 0s - loss: 1.9316e-04 - accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "426/426 - 0s - loss: 1.9074e-04 - accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "426/426 - 0s - loss: 1.8834e-04 - accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "426/426 - 0s - loss: 1.8603e-04 - accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "426/426 - 0s - loss: 1.8375e-04 - accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "426/426 - 0s - loss: 1.8151e-04 - accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "426/426 - 0s - loss: 1.7931e-04 - accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "426/426 - 0s - loss: 1.7712e-04 - accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "426/426 - 0s - loss: 1.7496e-04 - accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "426/426 - 0s - loss: 1.7287e-04 - accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "426/426 - 0s - loss: 1.7081e-04 - accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "426/426 - 0s - loss: 1.6877e-04 - accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "426/426 - 0s - loss: 1.6674e-04 - accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "426/426 - 0s - loss: 1.6476e-04 - accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "426/426 - 0s - loss: 1.6278e-04 - accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "426/426 - 0s - loss: 1.6085e-04 - accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "426/426 - 0s - loss: 1.5894e-04 - accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "426/426 - 0s - loss: 1.5706e-04 - accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "426/426 - 0s - loss: 1.5521e-04 - accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "426/426 - 0s - loss: 1.5342e-04 - accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "426/426 - 0s - loss: 1.5163e-04 - accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "426/426 - 0s - loss: 1.4986e-04 - accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "426/426 - 0s - loss: 1.4812e-04 - accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "426/426 - 0s - loss: 1.4639e-04 - accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "426/426 - 0s - loss: 1.4470e-04 - accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "426/426 - 0s - loss: 1.4301e-04 - accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "426/426 - 0s - loss: 1.4140e-04 - accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "426/426 - 0s - loss: 1.3977e-04 - accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "426/426 - 0s - loss: 1.3818e-04 - accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "426/426 - 0s - loss: 1.3659e-04 - accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "426/426 - 0s - loss: 1.3503e-04 - accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "426/426 - 0s - loss: 1.3348e-04 - accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "426/426 - 0s - loss: 1.3196e-04 - accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "426/426 - 0s - loss: 1.3046e-04 - accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "426/426 - 0s - loss: 1.2897e-04 - accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "426/426 - 0s - loss: 1.2751e-04 - accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "426/426 - 0s - loss: 1.2607e-04 - accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "426/426 - 0s - loss: 1.2464e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/1000\n",
      "426/426 - 0s - loss: 1.2324e-04 - accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "426/426 - 0s - loss: 1.2187e-04 - accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "426/426 - 0s - loss: 1.2050e-04 - accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "426/426 - 0s - loss: 1.1918e-04 - accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "426/426 - 0s - loss: 1.1786e-04 - accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "426/426 - 0s - loss: 1.1655e-04 - accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "426/426 - 0s - loss: 1.1526e-04 - accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "426/426 - 0s - loss: 1.1402e-04 - accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "426/426 - 0s - loss: 1.1277e-04 - accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "426/426 - 0s - loss: 1.1154e-04 - accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "426/426 - 0s - loss: 1.1031e-04 - accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "426/426 - 0s - loss: 1.0910e-04 - accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "426/426 - 0s - loss: 1.0791e-04 - accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "426/426 - 0s - loss: 1.0672e-04 - accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "426/426 - 0s - loss: 1.0557e-04 - accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "426/426 - 0s - loss: 1.0441e-04 - accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "426/426 - 0s - loss: 1.0327e-04 - accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "426/426 - 0s - loss: 1.0216e-04 - accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "426/426 - 0s - loss: 1.0106e-04 - accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "426/426 - 0s - loss: 9.9993e-05 - accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "426/426 - 0s - loss: 9.8911e-05 - accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "426/426 - 0s - loss: 9.7865e-05 - accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "426/426 - 0s - loss: 9.6831e-05 - accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "426/426 - 0s - loss: 9.5800e-05 - accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "426/426 - 0s - loss: 9.4765e-05 - accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "426/426 - 0s - loss: 9.3748e-05 - accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "426/426 - 0s - loss: 9.2749e-05 - accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "426/426 - 0s - loss: 9.1767e-05 - accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "426/426 - 0s - loss: 9.0817e-05 - accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "426/426 - 0s - loss: 8.9859e-05 - accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "426/426 - 0s - loss: 8.8921e-05 - accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "426/426 - 0s - loss: 8.7980e-05 - accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "426/426 - 0s - loss: 8.7051e-05 - accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "426/426 - 0s - loss: 8.6137e-05 - accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "426/426 - 0s - loss: 8.5239e-05 - accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "426/426 - 0s - loss: 8.4361e-05 - accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "426/426 - 0s - loss: 8.3473e-05 - accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "426/426 - 0s - loss: 8.2615e-05 - accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "426/426 - 0s - loss: 8.1754e-05 - accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "426/426 - 0s - loss: 8.0894e-05 - accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "426/426 - 0s - loss: 8.0054e-05 - accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "426/426 - 0s - loss: 7.9240e-05 - accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "426/426 - 0s - loss: 7.8419e-05 - accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "426/426 - 0s - loss: 7.7603e-05 - accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "426/426 - 0s - loss: 7.6820e-05 - accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "426/426 - 0s - loss: 7.6027e-05 - accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "426/426 - 0s - loss: 7.5252e-05 - accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "426/426 - 0s - loss: 7.4481e-05 - accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "426/426 - 0s - loss: 7.3716e-05 - accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "426/426 - 0s - loss: 7.2964e-05 - accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "426/426 - 0s - loss: 7.2212e-05 - accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "426/426 - 0s - loss: 7.1495e-05 - accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "426/426 - 0s - loss: 7.0761e-05 - accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "426/426 - 0s - loss: 7.0050e-05 - accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "426/426 - 0s - loss: 6.9339e-05 - accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "426/426 - 0s - loss: 6.8646e-05 - accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "426/426 - 0s - loss: 6.7957e-05 - accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "426/426 - 0s - loss: 6.7274e-05 - accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "426/426 - 0s - loss: 6.6605e-05 - accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "426/426 - 0s - loss: 6.5931e-05 - accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "426/426 - 0s - loss: 6.5285e-05 - accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "426/426 - 0s - loss: 6.4627e-05 - accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "426/426 - 0s - loss: 6.3983e-05 - accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "426/426 - 0s - loss: 6.3346e-05 - accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "426/426 - 0s - loss: 6.2713e-05 - accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "426/426 - 0s - loss: 6.2079e-05 - accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "426/426 - 0s - loss: 6.1458e-05 - accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "426/426 - 0s - loss: 6.0863e-05 - accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "426/426 - 0s - loss: 6.0254e-05 - accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "426/426 - 0s - loss: 5.9660e-05 - accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "426/426 - 0s - loss: 5.9070e-05 - accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "426/426 - 0s - loss: 5.8485e-05 - accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "426/426 - 0s - loss: 5.7917e-05 - accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "426/426 - 0s - loss: 5.7339e-05 - accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "426/426 - 0s - loss: 5.6784e-05 - accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "426/426 - 0s - loss: 5.6215e-05 - accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "426/426 - 0s - loss: 5.5660e-05 - accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "426/426 - 0s - loss: 5.5114e-05 - accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "426/426 - 0s - loss: 5.4577e-05 - accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "426/426 - 0s - loss: 5.4040e-05 - accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "426/426 - 0s - loss: 5.3510e-05 - accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "426/426 - 0s - loss: 5.2986e-05 - accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "426/426 - 0s - loss: 5.2470e-05 - accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "426/426 - 0s - loss: 5.1960e-05 - accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "426/426 - 0s - loss: 5.1462e-05 - accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "426/426 - 0s - loss: 5.0967e-05 - accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "426/426 - 0s - loss: 5.0469e-05 - accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "426/426 - 0s - loss: 4.9983e-05 - accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "426/426 - 0s - loss: 4.9509e-05 - accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "426/426 - 0s - loss: 4.9026e-05 - accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "426/426 - 0s - loss: 4.8553e-05 - accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "426/426 - 0s - loss: 4.8080e-05 - accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "426/426 - 0s - loss: 4.7627e-05 - accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "426/426 - 0s - loss: 4.7165e-05 - accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "426/426 - 0s - loss: 4.6717e-05 - accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "426/426 - 0s - loss: 4.6271e-05 - accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "426/426 - 0s - loss: 4.5826e-05 - accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "426/426 - 0s - loss: 4.5398e-05 - accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "426/426 - 0s - loss: 4.4963e-05 - accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "426/426 - 0s - loss: 4.4531e-05 - accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "426/426 - 0s - loss: 4.4116e-05 - accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "426/426 - 0s - loss: 4.3683e-05 - accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "426/426 - 0s - loss: 4.3272e-05 - accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "426/426 - 0s - loss: 4.2864e-05 - accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "426/426 - 0s - loss: 4.2454e-05 - accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "426/426 - 0s - loss: 4.2059e-05 - accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "426/426 - 0s - loss: 4.1658e-05 - accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "426/426 - 0s - loss: 4.1275e-05 - accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "426/426 - 0s - loss: 4.0885e-05 - accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "426/426 - 0s - loss: 4.0501e-05 - accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "426/426 - 0s - loss: 4.0122e-05 - accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "426/426 - 0s - loss: 3.9744e-05 - accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "426/426 - 0s - loss: 3.9375e-05 - accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "426/426 - 0s - loss: 3.9008e-05 - accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "426/426 - 0s - loss: 3.8648e-05 - accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "426/426 - 0s - loss: 3.8285e-05 - accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "426/426 - 0s - loss: 3.7935e-05 - accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "426/426 - 0s - loss: 3.7584e-05 - accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "426/426 - 0s - loss: 3.7226e-05 - accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "426/426 - 0s - loss: 3.6879e-05 - accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "426/426 - 0s - loss: 3.6541e-05 - accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "426/426 - 0s - loss: 3.6203e-05 - accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "426/426 - 0s - loss: 3.5868e-05 - accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "426/426 - 0s - loss: 3.5542e-05 - accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "426/426 - 0s - loss: 3.5213e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/1000\n",
      "426/426 - 0s - loss: 3.4883e-05 - accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "426/426 - 0s - loss: 3.4565e-05 - accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "426/426 - 0s - loss: 3.4241e-05 - accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "426/426 - 0s - loss: 3.3924e-05 - accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "426/426 - 0s - loss: 3.3615e-05 - accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "426/426 - 0s - loss: 3.3306e-05 - accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "426/426 - 0s - loss: 3.3007e-05 - accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "426/426 - 0s - loss: 3.2705e-05 - accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "426/426 - 0s - loss: 3.2394e-05 - accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "426/426 - 0s - loss: 3.2101e-05 - accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "426/426 - 0s - loss: 3.1813e-05 - accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "426/426 - 0s - loss: 3.1513e-05 - accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "426/426 - 0s - loss: 3.1226e-05 - accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "426/426 - 0s - loss: 3.0950e-05 - accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "426/426 - 0s - loss: 3.0652e-05 - accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "426/426 - 0s - loss: 3.0387e-05 - accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "426/426 - 0s - loss: 3.0101e-05 - accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "426/426 - 0s - loss: 2.9837e-05 - accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "426/426 - 0s - loss: 2.9551e-05 - accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "426/426 - 0s - loss: 2.9294e-05 - accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "426/426 - 0s - loss: 2.9022e-05 - accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "426/426 - 0s - loss: 2.8765e-05 - accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "426/426 - 0s - loss: 2.8494e-05 - accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "426/426 - 0s - loss: 2.8247e-05 - accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "426/426 - 0s - loss: 2.7983e-05 - accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "426/426 - 0s - loss: 2.7738e-05 - accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "426/426 - 0s - loss: 2.7486e-05 - accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "426/426 - 0s - loss: 2.7233e-05 - accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "426/426 - 0s - loss: 2.6998e-05 - accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "426/426 - 0s - loss: 2.6744e-05 - accuracy: 1.0000\n",
      "Epoch 414/1000\n",
      "426/426 - 0s - loss: 2.6509e-05 - accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "426/426 - 0s - loss: 2.6278e-05 - accuracy: 1.0000\n",
      "Epoch 416/1000\n",
      "426/426 - 0s - loss: 2.6035e-05 - accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "426/426 - 0s - loss: 2.5806e-05 - accuracy: 1.0000\n",
      "Epoch 418/1000\n",
      "426/426 - 0s - loss: 2.5573e-05 - accuracy: 1.0000\n",
      "Epoch 419/1000\n",
      "426/426 - 0s - loss: 2.5341e-05 - accuracy: 1.0000\n",
      "Epoch 420/1000\n",
      "426/426 - 0s - loss: 2.5118e-05 - accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "426/426 - 0s - loss: 2.4893e-05 - accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "426/426 - 0s - loss: 2.4670e-05 - accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "426/426 - 0s - loss: 2.4438e-05 - accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "426/426 - 0s - loss: 2.4220e-05 - accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "426/426 - 0s - loss: 2.4010e-05 - accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "426/426 - 0s - loss: 2.3795e-05 - accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "426/426 - 0s - loss: 2.3584e-05 - accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "426/426 - 0s - loss: 2.3369e-05 - accuracy: 1.0000\n",
      "Epoch 429/1000\n",
      "426/426 - 0s - loss: 2.3162e-05 - accuracy: 1.0000\n",
      "Epoch 430/1000\n",
      "426/426 - 0s - loss: 2.2963e-05 - accuracy: 1.0000\n",
      "Epoch 431/1000\n",
      "426/426 - 0s - loss: 2.2757e-05 - accuracy: 1.0000\n",
      "Epoch 432/1000\n",
      "426/426 - 0s - loss: 2.2556e-05 - accuracy: 1.0000\n",
      "Epoch 433/1000\n",
      "426/426 - 0s - loss: 2.2366e-05 - accuracy: 1.0000\n",
      "Epoch 434/1000\n",
      "426/426 - 0s - loss: 2.2153e-05 - accuracy: 1.0000\n",
      "Epoch 435/1000\n",
      "426/426 - 0s - loss: 2.1963e-05 - accuracy: 1.0000\n",
      "Epoch 436/1000\n",
      "426/426 - 0s - loss: 2.1768e-05 - accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "426/426 - 0s - loss: 2.1575e-05 - accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "426/426 - 0s - loss: 2.1386e-05 - accuracy: 1.0000\n",
      "Epoch 439/1000\n",
      "426/426 - 0s - loss: 2.1194e-05 - accuracy: 1.0000\n",
      "Epoch 440/1000\n",
      "426/426 - 0s - loss: 2.1008e-05 - accuracy: 1.0000\n",
      "Epoch 441/1000\n",
      "426/426 - 0s - loss: 2.0821e-05 - accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "426/426 - 0s - loss: 2.0641e-05 - accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "426/426 - 0s - loss: 2.0457e-05 - accuracy: 1.0000\n",
      "Epoch 444/1000\n",
      "426/426 - 0s - loss: 2.0273e-05 - accuracy: 1.0000\n",
      "Epoch 445/1000\n",
      "426/426 - 0s - loss: 2.0102e-05 - accuracy: 1.0000\n",
      "Epoch 446/1000\n",
      "426/426 - 0s - loss: 1.9924e-05 - accuracy: 1.0000\n",
      "Epoch 447/1000\n",
      "426/426 - 0s - loss: 1.9746e-05 - accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "426/426 - 0s - loss: 1.9577e-05 - accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "426/426 - 0s - loss: 1.9397e-05 - accuracy: 1.0000\n",
      "Epoch 450/1000\n",
      "426/426 - 0s - loss: 1.9231e-05 - accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "426/426 - 0s - loss: 1.9065e-05 - accuracy: 1.0000\n",
      "Epoch 452/1000\n",
      "426/426 - 0s - loss: 1.8899e-05 - accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "426/426 - 0s - loss: 1.8729e-05 - accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "426/426 - 0s - loss: 1.8565e-05 - accuracy: 1.0000\n",
      "Epoch 455/1000\n",
      "426/426 - 0s - loss: 1.8397e-05 - accuracy: 1.0000\n",
      "Epoch 456/1000\n",
      "426/426 - 0s - loss: 1.8232e-05 - accuracy: 1.0000\n",
      "Epoch 457/1000\n",
      "426/426 - 0s - loss: 1.8082e-05 - accuracy: 1.0000\n",
      "Epoch 458/1000\n",
      "426/426 - 0s - loss: 1.7919e-05 - accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "426/426 - 0s - loss: 1.7764e-05 - accuracy: 1.0000\n",
      "Epoch 460/1000\n",
      "426/426 - 0s - loss: 1.7613e-05 - accuracy: 1.0000\n",
      "Epoch 461/1000\n",
      "426/426 - 0s - loss: 1.7463e-05 - accuracy: 1.0000\n",
      "Epoch 462/1000\n",
      "426/426 - 0s - loss: 1.7311e-05 - accuracy: 1.0000\n",
      "Epoch 463/1000\n",
      "426/426 - 0s - loss: 1.7145e-05 - accuracy: 1.0000\n",
      "Epoch 464/1000\n",
      "426/426 - 0s - loss: 1.7001e-05 - accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "426/426 - 0s - loss: 1.6859e-05 - accuracy: 1.0000\n",
      "Epoch 466/1000\n",
      "426/426 - 0s - loss: 1.6713e-05 - accuracy: 1.0000\n",
      "Epoch 467/1000\n",
      "426/426 - 0s - loss: 1.6573e-05 - accuracy: 1.0000\n",
      "Epoch 468/1000\n",
      "426/426 - 0s - loss: 1.6429e-05 - accuracy: 1.0000\n",
      "Epoch 469/1000\n",
      "426/426 - 0s - loss: 1.6270e-05 - accuracy: 1.0000\n",
      "Epoch 470/1000\n",
      "426/426 - 0s - loss: 1.6134e-05 - accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "426/426 - 0s - loss: 1.6005e-05 - accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "426/426 - 0s - loss: 1.5869e-05 - accuracy: 1.0000\n",
      "Epoch 473/1000\n",
      "426/426 - 0s - loss: 1.5723e-05 - accuracy: 1.0000\n",
      "Epoch 474/1000\n",
      "426/426 - 0s - loss: 1.5577e-05 - accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "426/426 - 0s - loss: 1.5452e-05 - accuracy: 1.0000\n",
      "Epoch 476/1000\n",
      "426/426 - 0s - loss: 1.5325e-05 - accuracy: 1.0000\n",
      "Epoch 477/1000\n",
      "426/426 - 0s - loss: 1.5190e-05 - accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "426/426 - 0s - loss: 1.5047e-05 - accuracy: 1.0000\n",
      "Epoch 479/1000\n",
      "426/426 - 0s - loss: 1.4935e-05 - accuracy: 1.0000\n",
      "Epoch 480/1000\n",
      "426/426 - 0s - loss: 1.4814e-05 - accuracy: 1.0000\n",
      "Epoch 481/1000\n",
      "426/426 - 0s - loss: 1.4662e-05 - accuracy: 1.0000\n",
      "Epoch 482/1000\n",
      "426/426 - 0s - loss: 1.4538e-05 - accuracy: 1.0000\n",
      "Epoch 483/1000\n",
      "426/426 - 0s - loss: 1.4428e-05 - accuracy: 1.0000\n",
      "Epoch 484/1000\n",
      "426/426 - 0s - loss: 1.4295e-05 - accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "426/426 - 0s - loss: 1.4162e-05 - accuracy: 1.0000\n",
      "Epoch 486/1000\n",
      "426/426 - 0s - loss: 1.4062e-05 - accuracy: 1.0000\n",
      "Epoch 487/1000\n",
      "426/426 - 0s - loss: 1.3933e-05 - accuracy: 1.0000\n",
      "Epoch 488/1000\n",
      "426/426 - 0s - loss: 1.3808e-05 - accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "426/426 - 0s - loss: 1.3700e-05 - accuracy: 1.0000\n",
      "Epoch 490/1000\n",
      "426/426 - 0s - loss: 1.3583e-05 - accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "426/426 - 0s - loss: 1.3454e-05 - accuracy: 1.0000\n",
      "Epoch 492/1000\n",
      "426/426 - 0s - loss: 1.3357e-05 - accuracy: 1.0000\n",
      "Epoch 493/1000\n",
      "426/426 - 0s - loss: 1.3234e-05 - accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "426/426 - 0s - loss: 1.3111e-05 - accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "426/426 - 0s - loss: 1.3024e-05 - accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "426/426 - 0s - loss: 1.2888e-05 - accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "426/426 - 0s - loss: 1.2791e-05 - accuracy: 1.0000\n",
      "Epoch 498/1000\n",
      "426/426 - 0s - loss: 1.2688e-05 - accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "426/426 - 0s - loss: 1.2558e-05 - accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "426/426 - 0s - loss: 1.2477e-05 - accuracy: 1.0000\n",
      "Epoch 501/1000\n",
      "426/426 - 0s - loss: 1.2349e-05 - accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "426/426 - 0s - loss: 1.2250e-05 - accuracy: 1.0000\n",
      "Epoch 503/1000\n",
      "426/426 - 0s - loss: 1.2154e-05 - accuracy: 1.0000\n",
      "Epoch 504/1000\n",
      "426/426 - 0s - loss: 1.2030e-05 - accuracy: 1.0000\n",
      "Epoch 505/1000\n",
      "426/426 - 0s - loss: 1.1959e-05 - accuracy: 1.0000\n",
      "Epoch 506/1000\n",
      "426/426 - 0s - loss: 1.1823e-05 - accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "426/426 - 0s - loss: 1.1750e-05 - accuracy: 1.0000\n",
      "Epoch 508/1000\n",
      "426/426 - 0s - loss: 1.1636e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509/1000\n",
      "426/426 - 0s - loss: 1.1538e-05 - accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "426/426 - 0s - loss: 1.1444e-05 - accuracy: 1.0000\n",
      "Epoch 511/1000\n",
      "426/426 - 0s - loss: 1.1344e-05 - accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "426/426 - 0s - loss: 1.1257e-05 - accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "426/426 - 0s - loss: 1.1149e-05 - accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "426/426 - 0s - loss: 1.1073e-05 - accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "426/426 - 0s - loss: 1.0951e-05 - accuracy: 1.0000\n",
      "Epoch 516/1000\n",
      "426/426 - 0s - loss: 1.0887e-05 - accuracy: 1.0000\n",
      "Epoch 517/1000\n",
      "426/426 - 0s - loss: 1.0763e-05 - accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "426/426 - 0s - loss: 1.0709e-05 - accuracy: 1.0000\n",
      "Epoch 519/1000\n",
      "426/426 - 0s - loss: 1.0582e-05 - accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "426/426 - 0s - loss: 1.0529e-05 - accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "426/426 - 0s - loss: 1.0404e-05 - accuracy: 1.0000\n",
      "Epoch 522/1000\n",
      "426/426 - 0s - loss: 1.0352e-05 - accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "426/426 - 0s - loss: 1.0224e-05 - accuracy: 1.0000\n",
      "Epoch 524/1000\n",
      "426/426 - 0s - loss: 1.0174e-05 - accuracy: 1.0000\n",
      "Epoch 525/1000\n",
      "426/426 - 0s - loss: 1.0059e-05 - accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "426/426 - 0s - loss: 1.0001e-05 - accuracy: 1.0000\n",
      "Epoch 527/1000\n",
      "426/426 - 0s - loss: 9.8924e-06 - accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "426/426 - 0s - loss: 9.8286e-06 - accuracy: 1.0000\n",
      "Epoch 529/1000\n",
      "426/426 - 0s - loss: 9.7328e-06 - accuracy: 1.0000\n",
      "Epoch 530/1000\n",
      "426/426 - 0s - loss: 9.6598e-06 - accuracy: 1.0000\n",
      "Epoch 531/1000\n",
      "426/426 - 0s - loss: 9.5761e-06 - accuracy: 1.0000\n",
      "Epoch 532/1000\n",
      "426/426 - 0s - loss: 9.4908e-06 - accuracy: 1.0000\n",
      "Epoch 533/1000\n",
      "426/426 - 0s - loss: 9.4276e-06 - accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "426/426 - 0s - loss: 9.3204e-06 - accuracy: 1.0000\n",
      "Epoch 535/1000\n",
      "426/426 - 0s - loss: 9.2787e-06 - accuracy: 1.0000\n",
      "Epoch 536/1000\n",
      "426/426 - 0s - loss: 9.1600e-06 - accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "426/426 - 0s - loss: 9.1136e-06 - accuracy: 1.0000\n",
      "Epoch 538/1000\n",
      "426/426 - 0s - loss: 9.0201e-06 - accuracy: 1.0000\n",
      "Epoch 539/1000\n",
      "426/426 - 0s - loss: 8.9488e-06 - accuracy: 1.0000\n",
      "Epoch 540/1000\n",
      "426/426 - 0s - loss: 8.8878e-06 - accuracy: 1.0000\n",
      "Epoch 541/1000\n",
      "426/426 - 0s - loss: 8.7862e-06 - accuracy: 1.0000\n",
      "Epoch 542/1000\n",
      "426/426 - 0s - loss: 8.7403e-06 - accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "426/426 - 0s - loss: 8.6379e-06 - accuracy: 1.0000\n",
      "Epoch 544/1000\n",
      "426/426 - 0s - loss: 8.5864e-06 - accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "426/426 - 0s - loss: 8.5153e-06 - accuracy: 1.0000\n",
      "Epoch 546/1000\n",
      "426/426 - 0s - loss: 8.4277e-06 - accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "426/426 - 0s - loss: 8.3888e-06 - accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "426/426 - 0s - loss: 8.2875e-06 - accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "426/426 - 0s - loss: 8.2330e-06 - accuracy: 1.0000\n",
      "Epoch 550/1000\n",
      "426/426 - 0s - loss: 8.1759e-06 - accuracy: 1.0000\n",
      "Epoch 551/1000\n",
      "426/426 - 0s - loss: 8.0813e-06 - accuracy: 1.0000\n",
      "Epoch 552/1000\n",
      "426/426 - 0s - loss: 8.0360e-06 - accuracy: 1.0000\n",
      "Epoch 553/1000\n",
      "426/426 - 0s - loss: 7.9495e-06 - accuracy: 1.0000\n",
      "Epoch 554/1000\n",
      "426/426 - 0s - loss: 7.8860e-06 - accuracy: 1.0000\n",
      "Epoch 555/1000\n",
      "426/426 - 0s - loss: 7.8485e-06 - accuracy: 1.0000\n",
      "Epoch 556/1000\n",
      "426/426 - 0s - loss: 7.7424e-06 - accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "426/426 - 0s - loss: 7.6974e-06 - accuracy: 1.0000\n",
      "Epoch 558/1000\n",
      "426/426 - 0s - loss: 7.6520e-06 - accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "426/426 - 0s - loss: 7.5513e-06 - accuracy: 1.0000\n",
      "Epoch 560/1000\n",
      "426/426 - 0s - loss: 7.5076e-06 - accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "426/426 - 0s - loss: 7.4500e-06 - accuracy: 1.0000\n",
      "Epoch 562/1000\n",
      "426/426 - 0s - loss: 7.3652e-06 - accuracy: 1.0000\n",
      "Epoch 563/1000\n",
      "426/426 - 0s - loss: 7.3322e-06 - accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "426/426 - 0s - loss: 7.2723e-06 - accuracy: 1.0000\n",
      "Epoch 565/1000\n",
      "426/426 - 0s - loss: 7.1830e-06 - accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "426/426 - 0s - loss: 7.1478e-06 - accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "426/426 - 0s - loss: 7.0862e-06 - accuracy: 1.0000\n",
      "Epoch 568/1000\n",
      "426/426 - 0s - loss: 7.0109e-06 - accuracy: 1.0000\n",
      "Epoch 569/1000\n",
      "426/426 - 0s - loss: 6.9765e-06 - accuracy: 1.0000\n",
      "Epoch 570/1000\n",
      "426/426 - 0s - loss: 6.9122e-06 - accuracy: 1.0000\n",
      "Epoch 571/1000\n",
      "426/426 - 0s - loss: 6.8290e-06 - accuracy: 1.0000\n",
      "Epoch 572/1000\n",
      "426/426 - 0s - loss: 6.7977e-06 - accuracy: 1.0000\n",
      "Epoch 573/1000\n",
      "426/426 - 0s - loss: 6.7591e-06 - accuracy: 1.0000\n",
      "Epoch 574/1000\n",
      "426/426 - 0s - loss: 6.6539e-06 - accuracy: 1.0000\n",
      "Epoch 575/1000\n",
      "426/426 - 0s - loss: 6.6217e-06 - accuracy: 1.0000\n",
      "Epoch 576/1000\n",
      "426/426 - 0s - loss: 6.5917e-06 - accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "426/426 - 0s - loss: 6.4994e-06 - accuracy: 1.0000\n",
      "Epoch 578/1000\n",
      "426/426 - 0s - loss: 6.4485e-06 - accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "426/426 - 0s - loss: 6.4213e-06 - accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "426/426 - 0s - loss: 6.3556e-06 - accuracy: 1.0000\n",
      "Epoch 581/1000\n",
      "426/426 - 0s - loss: 6.2864e-06 - accuracy: 1.0000\n",
      "Epoch 582/1000\n",
      "426/426 - 0s - loss: 6.2509e-06 - accuracy: 1.0000\n",
      "Epoch 583/1000\n",
      "426/426 - 0s - loss: 6.2238e-06 - accuracy: 1.0000\n",
      "Epoch 584/1000\n",
      "426/426 - 0s - loss: 6.1239e-06 - accuracy: 1.0000\n",
      "Epoch 585/1000\n",
      "426/426 - 0s - loss: 6.0906e-06 - accuracy: 1.0000\n",
      "Epoch 586/1000\n",
      "426/426 - 0s - loss: 6.0696e-06 - accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "426/426 - 0s - loss: 5.9884e-06 - accuracy: 1.0000\n",
      "Epoch 588/1000\n",
      "426/426 - 0s - loss: 5.9305e-06 - accuracy: 1.0000\n",
      "Epoch 589/1000\n",
      "426/426 - 0s - loss: 5.9120e-06 - accuracy: 1.0000\n",
      "Epoch 590/1000\n",
      "426/426 - 0s - loss: 5.8734e-06 - accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "426/426 - 0s - loss: 5.7744e-06 - accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "426/426 - 0s - loss: 5.7545e-06 - accuracy: 1.0000\n",
      "Epoch 593/1000\n",
      "426/426 - 0s - loss: 5.7117e-06 - accuracy: 1.0000\n",
      "Epoch 594/1000\n",
      "426/426 - 0s - loss: 5.6770e-06 - accuracy: 1.0000\n",
      "Epoch 595/1000\n",
      "426/426 - 0s - loss: 5.5927e-06 - accuracy: 1.0000\n",
      "Epoch 596/1000\n",
      "426/426 - 0s - loss: 5.5600e-06 - accuracy: 1.0000\n",
      "Epoch 597/1000\n",
      "426/426 - 0s - loss: 5.5441e-06 - accuracy: 1.0000\n",
      "Epoch 598/1000\n",
      "426/426 - 0s - loss: 5.4850e-06 - accuracy: 1.0000\n",
      "Epoch 599/1000\n",
      "426/426 - 0s - loss: 5.4156e-06 - accuracy: 1.0000\n",
      "Epoch 600/1000\n",
      "426/426 - 0s - loss: 5.3868e-06 - accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "426/426 - 0s - loss: 5.3568e-06 - accuracy: 1.0000\n",
      "Epoch 602/1000\n",
      "426/426 - 0s - loss: 5.3188e-06 - accuracy: 1.0000\n",
      "Epoch 603/1000\n",
      "426/426 - 0s - loss: 5.2264e-06 - accuracy: 1.0000\n",
      "Epoch 604/1000\n",
      "426/426 - 0s - loss: 5.2155e-06 - accuracy: 1.0000\n",
      "Epoch 605/1000\n",
      "426/426 - 0s - loss: 5.1808e-06 - accuracy: 1.0000\n",
      "Epoch 606/1000\n",
      "426/426 - 0s - loss: 5.1531e-06 - accuracy: 1.0000\n",
      "Epoch 607/1000\n",
      "426/426 - 0s - loss: 5.0641e-06 - accuracy: 1.0000\n",
      "Epoch 608/1000\n",
      "426/426 - 0s - loss: 5.0328e-06 - accuracy: 1.0000\n",
      "Epoch 609/1000\n",
      "426/426 - 0s - loss: 5.0185e-06 - accuracy: 1.0000\n",
      "Epoch 610/1000\n",
      "426/426 - 0s - loss: 4.9810e-06 - accuracy: 1.0000\n",
      "Epoch 611/1000\n",
      "426/426 - 0s - loss: 4.9150e-06 - accuracy: 1.0000\n",
      "Epoch 612/1000\n",
      "426/426 - 0s - loss: 4.8573e-06 - accuracy: 1.0000\n",
      "Epoch 613/1000\n",
      "426/426 - 0s - loss: 4.8456e-06 - accuracy: 1.0000\n",
      "Epoch 614/1000\n",
      "426/426 - 0s - loss: 4.8134e-06 - accuracy: 1.0000\n",
      "Epoch 615/1000\n",
      "426/426 - 0s - loss: 4.7826e-06 - accuracy: 1.0000\n",
      "Epoch 616/1000\n",
      "426/426 - 0s - loss: 4.6964e-06 - accuracy: 1.0000\n",
      "Epoch 617/1000\n",
      "426/426 - 0s - loss: 4.6777e-06 - accuracy: 1.0000\n",
      "Epoch 618/1000\n",
      "426/426 - 0s - loss: 4.6514e-06 - accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "426/426 - 0s - loss: 4.6329e-06 - accuracy: 1.0000\n",
      "Epoch 620/1000\n",
      "426/426 - 0s - loss: 4.5627e-06 - accuracy: 1.0000\n",
      "Epoch 621/1000\n",
      "426/426 - 0s - loss: 4.5137e-06 - accuracy: 1.0000\n",
      "Epoch 622/1000\n",
      "426/426 - 0s - loss: 4.4891e-06 - accuracy: 1.0000\n",
      "Epoch 623/1000\n",
      "426/426 - 0s - loss: 4.4687e-06 - accuracy: 1.0000\n",
      "Epoch 624/1000\n",
      "426/426 - 0s - loss: 4.4460e-06 - accuracy: 1.0000\n",
      "Epoch 625/1000\n",
      "426/426 - 0s - loss: 4.3766e-06 - accuracy: 1.0000\n",
      "Epoch 626/1000\n",
      "426/426 - 0s - loss: 4.3282e-06 - accuracy: 1.0000\n",
      "Epoch 627/1000\n",
      "426/426 - 0s - loss: 4.3117e-06 - accuracy: 1.0000\n",
      "Epoch 628/1000\n",
      "426/426 - 0s - loss: 4.2834e-06 - accuracy: 1.0000\n",
      "Epoch 629/1000\n",
      "426/426 - 0s - loss: 4.2753e-06 - accuracy: 1.0000\n",
      "Epoch 630/1000\n",
      "426/426 - 0s - loss: 4.1964e-06 - accuracy: 1.0000\n",
      "Epoch 631/1000\n",
      "426/426 - 0s - loss: 4.1650e-06 - accuracy: 1.0000\n",
      "Epoch 632/1000\n",
      "426/426 - 0s - loss: 4.1225e-06 - accuracy: 1.0000\n",
      "Epoch 633/1000\n",
      "426/426 - 0s - loss: 4.1211e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 634/1000\n",
      "426/426 - 0s - loss: 4.0867e-06 - accuracy: 1.0000\n",
      "Epoch 635/1000\n",
      "426/426 - 0s - loss: 4.0593e-06 - accuracy: 1.0000\n",
      "Epoch 636/1000\n",
      "426/426 - 0s - loss: 3.9781e-06 - accuracy: 1.0000\n",
      "Epoch 637/1000\n",
      "426/426 - 0s - loss: 3.9594e-06 - accuracy: 1.0000\n",
      "Epoch 638/1000\n",
      "426/426 - 0s - loss: 3.9487e-06 - accuracy: 1.0000\n",
      "Epoch 639/1000\n",
      "426/426 - 0s - loss: 3.9163e-06 - accuracy: 1.0000\n",
      "Epoch 640/1000\n",
      "426/426 - 0s - loss: 3.9154e-06 - accuracy: 1.0000\n",
      "Epoch 641/1000\n",
      "426/426 - 0s - loss: 3.8270e-06 - accuracy: 1.0000\n",
      "Epoch 642/1000\n",
      "426/426 - 0s - loss: 3.7985e-06 - accuracy: 1.0000\n",
      "Epoch 643/1000\n",
      "426/426 - 0s - loss: 3.7769e-06 - accuracy: 1.0000\n",
      "Epoch 644/1000\n",
      "426/426 - 0s - loss: 3.7540e-06 - accuracy: 1.0000\n",
      "Epoch 645/1000\n",
      "426/426 - 0s - loss: 3.7492e-06 - accuracy: 1.0000\n",
      "Epoch 646/1000\n",
      "426/426 - 0s - loss: 3.7112e-06 - accuracy: 1.0000\n",
      "Epoch 647/1000\n",
      "426/426 - 0s - loss: 3.6479e-06 - accuracy: 1.0000\n",
      "Epoch 648/1000\n",
      "426/426 - 0s - loss: 3.6101e-06 - accuracy: 1.0000\n",
      "Epoch 649/1000\n",
      "426/426 - 0s - loss: 3.5911e-06 - accuracy: 1.0000\n",
      "Epoch 650/1000\n",
      "426/426 - 0s - loss: 3.5911e-06 - accuracy: 1.0000\n",
      "Epoch 651/1000\n",
      "426/426 - 0s - loss: 3.5486e-06 - accuracy: 1.0000\n",
      "Epoch 652/1000\n",
      "426/426 - 0s - loss: 3.5486e-06 - accuracy: 1.0000\n",
      "Epoch 653/1000\n",
      "426/426 - 0s - loss: 3.4764e-06 - accuracy: 1.0000\n",
      "Epoch 654/1000\n",
      "426/426 - 0s - loss: 3.4308e-06 - accuracy: 1.0000\n",
      "Epoch 655/1000\n",
      "426/426 - 0s - loss: 3.4288e-06 - accuracy: 1.0000\n",
      "Epoch 656/1000\n",
      "426/426 - 0s - loss: 3.4003e-06 - accuracy: 1.0000\n",
      "Epoch 657/1000\n",
      "426/426 - 0s - loss: 3.3863e-06 - accuracy: 1.0000\n",
      "Epoch 658/1000\n",
      "426/426 - 0s - loss: 3.3857e-06 - accuracy: 1.0000\n",
      "Epoch 659/1000\n",
      "426/426 - 0s - loss: 3.3241e-06 - accuracy: 1.0000\n",
      "Epoch 660/1000\n",
      "426/426 - 0s - loss: 3.2690e-06 - accuracy: 1.0000\n",
      "Epoch 661/1000\n",
      "426/426 - 0s - loss: 3.2665e-06 - accuracy: 1.0000\n",
      "Epoch 662/1000\n",
      "426/426 - 0s - loss: 3.2242e-06 - accuracy: 1.0000\n",
      "Epoch 663/1000\n",
      "426/426 - 0s - loss: 3.2240e-06 - accuracy: 1.0000\n",
      "Epoch 664/1000\n",
      "426/426 - 0s - loss: 3.2150e-06 - accuracy: 1.0000\n",
      "Epoch 665/1000\n",
      "426/426 - 0s - loss: 3.1809e-06 - accuracy: 1.0000\n",
      "Epoch 666/1000\n",
      "426/426 - 0s - loss: 3.1423e-06 - accuracy: 1.0000\n",
      "Epoch 667/1000\n",
      "426/426 - 0s - loss: 3.0958e-06 - accuracy: 1.0000\n",
      "Epoch 668/1000\n",
      "426/426 - 0s - loss: 3.0619e-06 - accuracy: 1.0000\n",
      "Epoch 669/1000\n",
      "426/426 - 0s - loss: 3.0617e-06 - accuracy: 1.0000\n",
      "Epoch 670/1000\n",
      "426/426 - 0s - loss: 3.0521e-06 - accuracy: 1.0000\n",
      "Epoch 671/1000\n",
      "426/426 - 0s - loss: 3.0186e-06 - accuracy: 1.0000\n",
      "Epoch 672/1000\n",
      "426/426 - 0s - loss: 3.0183e-06 - accuracy: 1.0000\n",
      "Epoch 673/1000\n",
      "426/426 - 0s - loss: 2.9956e-06 - accuracy: 1.0000\n",
      "Epoch 674/1000\n",
      "426/426 - 0s - loss: 2.9013e-06 - accuracy: 1.0000\n",
      "Epoch 675/1000\n",
      "426/426 - 0s - loss: 2.9002e-06 - accuracy: 1.0000\n",
      "Epoch 676/1000\n",
      "426/426 - 0s - loss: 2.8985e-06 - accuracy: 1.0000\n",
      "Epoch 677/1000\n",
      "426/426 - 0s - loss: 2.8571e-06 - accuracy: 1.0000\n",
      "Epoch 678/1000\n",
      "426/426 - 0s - loss: 2.8563e-06 - accuracy: 1.0000\n",
      "Epoch 679/1000\n",
      "426/426 - 0s - loss: 2.8551e-06 - accuracy: 1.0000\n",
      "Epoch 680/1000\n",
      "426/426 - 0s - loss: 2.8235e-06 - accuracy: 1.0000\n",
      "Epoch 681/1000\n",
      "426/426 - 0s - loss: 2.7704e-06 - accuracy: 1.0000\n",
      "Epoch 682/1000\n",
      "426/426 - 0s - loss: 2.7379e-06 - accuracy: 1.0000\n",
      "Epoch 683/1000\n",
      "426/426 - 0s - loss: 2.7222e-06 - accuracy: 1.0000\n",
      "Epoch 684/1000\n",
      "426/426 - 0s - loss: 2.6942e-06 - accuracy: 1.0000\n",
      "Epoch 685/1000\n",
      "426/426 - 0s - loss: 2.6937e-06 - accuracy: 1.0000\n",
      "Epoch 686/1000\n",
      "426/426 - 0s - loss: 2.6931e-06 - accuracy: 1.0000\n",
      "Epoch 687/1000\n",
      "426/426 - 0s - loss: 2.6548e-06 - accuracy: 1.0000\n",
      "Epoch 688/1000\n",
      "426/426 - 0s - loss: 2.6511e-06 - accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "426/426 - 0s - loss: 2.6223e-06 - accuracy: 1.0000\n",
      "Epoch 690/1000\n",
      "426/426 - 0s - loss: 2.5633e-06 - accuracy: 1.0000\n",
      "Epoch 691/1000\n",
      "426/426 - 0s - loss: 2.5322e-06 - accuracy: 1.0000\n",
      "Epoch 692/1000\n",
      "426/426 - 0s - loss: 2.5317e-06 - accuracy: 1.0000\n",
      "Epoch 693/1000\n",
      "426/426 - 0s - loss: 2.5308e-06 - accuracy: 1.0000\n",
      "Epoch 694/1000\n",
      "426/426 - 0s - loss: 2.5017e-06 - accuracy: 1.0000\n",
      "Epoch 695/1000\n",
      "426/426 - 0s - loss: 2.4886e-06 - accuracy: 1.0000\n",
      "Epoch 696/1000\n",
      "426/426 - 0s - loss: 2.4880e-06 - accuracy: 1.0000\n",
      "Epoch 697/1000\n",
      "426/426 - 0s - loss: 2.4877e-06 - accuracy: 1.0000\n",
      "Epoch 698/1000\n",
      "426/426 - 0s - loss: 2.4071e-06 - accuracy: 1.0000\n",
      "Epoch 699/1000\n",
      "426/426 - 0s - loss: 2.3713e-06 - accuracy: 1.0000\n",
      "Epoch 700/1000\n",
      "426/426 - 0s - loss: 2.3696e-06 - accuracy: 1.0000\n",
      "Epoch 701/1000\n",
      "426/426 - 0s - loss: 2.3674e-06 - accuracy: 1.0000\n",
      "Epoch 702/1000\n",
      "426/426 - 0s - loss: 2.3277e-06 - accuracy: 1.0000\n",
      "Epoch 703/1000\n",
      "426/426 - 0s - loss: 2.3265e-06 - accuracy: 1.0000\n",
      "Epoch 704/1000\n",
      "426/426 - 0s - loss: 2.3257e-06 - accuracy: 1.0000\n",
      "Epoch 705/1000\n",
      "426/426 - 0s - loss: 2.3254e-06 - accuracy: 1.0000\n",
      "Epoch 706/1000\n",
      "426/426 - 0s - loss: 2.2837e-06 - accuracy: 1.0000\n",
      "Epoch 707/1000\n",
      "426/426 - 0s - loss: 2.2834e-06 - accuracy: 1.0000\n",
      "Epoch 708/1000\n",
      "426/426 - 0s - loss: 2.2084e-06 - accuracy: 1.0000\n",
      "Epoch 709/1000\n",
      "426/426 - 0s - loss: 2.2070e-06 - accuracy: 1.0000\n",
      "Epoch 710/1000\n",
      "426/426 - 0s - loss: 2.1654e-06 - accuracy: 1.0000\n",
      "Epoch 711/1000\n",
      "426/426 - 0s - loss: 2.1640e-06 - accuracy: 1.0000\n",
      "Epoch 712/1000\n",
      "426/426 - 0s - loss: 2.1634e-06 - accuracy: 1.0000\n",
      "Epoch 713/1000\n",
      "426/426 - 0s - loss: 2.1634e-06 - accuracy: 1.0000\n",
      "Epoch 714/1000\n",
      "426/426 - 0s - loss: 2.1337e-06 - accuracy: 1.0000\n",
      "Epoch 715/1000\n",
      "426/426 - 0s - loss: 2.1211e-06 - accuracy: 1.0000\n",
      "Epoch 716/1000\n",
      "426/426 - 0s - loss: 2.1206e-06 - accuracy: 1.0000\n",
      "Epoch 717/1000\n",
      "426/426 - 0s - loss: 2.1200e-06 - accuracy: 1.0000\n",
      "Epoch 718/1000\n",
      "426/426 - 0s - loss: 2.0629e-06 - accuracy: 1.0000\n",
      "Epoch 719/1000\n",
      "426/426 - 0s - loss: 2.0042e-06 - accuracy: 1.0000\n",
      "Epoch 720/1000\n",
      "426/426 - 0s - loss: 2.0017e-06 - accuracy: 1.0000\n",
      "Epoch 721/1000\n",
      "426/426 - 0s - loss: 2.0014e-06 - accuracy: 1.0000\n",
      "Epoch 722/1000\n",
      "426/426 - 0s - loss: 2.0008e-06 - accuracy: 1.0000\n",
      "Epoch 723/1000\n",
      "426/426 - 0s - loss: 1.9689e-06 - accuracy: 1.0000\n",
      "Epoch 724/1000\n",
      "426/426 - 0s - loss: 1.9588e-06 - accuracy: 1.0000\n",
      "Epoch 725/1000\n",
      "426/426 - 0s - loss: 1.9583e-06 - accuracy: 1.0000\n",
      "Epoch 726/1000\n",
      "426/426 - 0s - loss: 1.9577e-06 - accuracy: 1.0000\n",
      "Epoch 727/1000\n",
      "426/426 - 0s - loss: 1.9577e-06 - accuracy: 1.0000\n",
      "Epoch 728/1000\n",
      "426/426 - 0s - loss: 1.9166e-06 - accuracy: 1.0000\n",
      "Epoch 729/1000\n",
      "426/426 - 0s - loss: 1.8973e-06 - accuracy: 1.0000\n",
      "Epoch 730/1000\n",
      "426/426 - 0s - loss: 1.8413e-06 - accuracy: 1.0000\n",
      "Epoch 731/1000\n",
      "426/426 - 0s - loss: 1.8396e-06 - accuracy: 1.0000\n",
      "Epoch 732/1000\n",
      "426/426 - 0s - loss: 1.8377e-06 - accuracy: 1.0000\n",
      "Epoch 733/1000\n",
      "426/426 - 0s - loss: 1.7971e-06 - accuracy: 1.0000\n",
      "Epoch 734/1000\n",
      "426/426 - 0s - loss: 1.7968e-06 - accuracy: 1.0000\n",
      "Epoch 735/1000\n",
      "426/426 - 0s - loss: 1.7954e-06 - accuracy: 1.0000\n",
      "Epoch 736/1000\n",
      "426/426 - 0s - loss: 1.7954e-06 - accuracy: 1.0000\n",
      "Epoch 737/1000\n",
      "426/426 - 0s - loss: 1.7954e-06 - accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "426/426 - 0s - loss: 1.7607e-06 - accuracy: 1.0000\n",
      "Epoch 739/1000\n",
      "426/426 - 0s - loss: 1.7534e-06 - accuracy: 1.0000\n",
      "Epoch 740/1000\n",
      "426/426 - 0s - loss: 1.7529e-06 - accuracy: 1.0000\n",
      "Epoch 741/1000\n",
      "426/426 - 0s - loss: 1.7529e-06 - accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "426/426 - 0s - loss: 1.6955e-06 - accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "426/426 - 0s - loss: 1.6661e-06 - accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "426/426 - 0s - loss: 1.6351e-06 - accuracy: 1.0000\n",
      "Epoch 745/1000\n",
      "426/426 - 0s - loss: 1.6339e-06 - accuracy: 1.0000\n",
      "Epoch 746/1000\n",
      "426/426 - 0s - loss: 1.6337e-06 - accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "426/426 - 0s - loss: 1.6334e-06 - accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "426/426 - 0s - loss: 1.6331e-06 - accuracy: 1.0000\n",
      "Epoch 749/1000\n",
      "426/426 - 0s - loss: 1.6085e-06 - accuracy: 1.0000\n",
      "Epoch 750/1000\n",
      "426/426 - 0s - loss: 1.5911e-06 - accuracy: 1.0000\n",
      "Epoch 751/1000\n",
      "426/426 - 0s - loss: 1.5911e-06 - accuracy: 1.0000\n",
      "Epoch 752/1000\n",
      "426/426 - 0s - loss: 1.5906e-06 - accuracy: 1.0000\n",
      "Epoch 753/1000\n",
      "426/426 - 0s - loss: 1.5900e-06 - accuracy: 1.0000\n",
      "Epoch 754/1000\n",
      "426/426 - 0s - loss: 1.5900e-06 - accuracy: 1.0000\n",
      "Epoch 755/1000\n",
      "426/426 - 0s - loss: 1.5629e-06 - accuracy: 1.0000\n",
      "Epoch 756/1000\n",
      "426/426 - 0s - loss: 1.4806e-06 - accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "426/426 - 0s - loss: 1.4725e-06 - accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "426/426 - 0s - loss: 1.4714e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 759/1000\n",
      "426/426 - 0s - loss: 1.4714e-06 - accuracy: 1.0000\n",
      "Epoch 760/1000\n",
      "426/426 - 0s - loss: 1.4711e-06 - accuracy: 1.0000\n",
      "Epoch 761/1000\n",
      "426/426 - 0s - loss: 1.4588e-06 - accuracy: 1.0000\n",
      "Epoch 762/1000\n",
      "426/426 - 0s - loss: 1.4291e-06 - accuracy: 1.0000\n",
      "Epoch 763/1000\n",
      "426/426 - 0s - loss: 1.4288e-06 - accuracy: 1.0000\n",
      "Epoch 764/1000\n",
      "426/426 - 0s - loss: 1.4283e-06 - accuracy: 1.0000\n",
      "Epoch 765/1000\n",
      "426/426 - 0s - loss: 1.4277e-06 - accuracy: 1.0000\n",
      "Epoch 766/1000\n",
      "426/426 - 0s - loss: 1.4277e-06 - accuracy: 1.0000\n",
      "Epoch 767/1000\n",
      "426/426 - 0s - loss: 1.4277e-06 - accuracy: 1.0000\n",
      "Epoch 768/1000\n",
      "426/426 - 0s - loss: 1.4028e-06 - accuracy: 1.0000\n",
      "Epoch 769/1000\n",
      "426/426 - 0s - loss: 1.3857e-06 - accuracy: 1.0000\n",
      "Epoch 770/1000\n",
      "426/426 - 0s - loss: 1.3855e-06 - accuracy: 1.0000\n",
      "Epoch 771/1000\n",
      "426/426 - 0s - loss: 1.3603e-06 - accuracy: 1.0000\n",
      "Epoch 772/1000\n",
      "426/426 - 0s - loss: 1.3110e-06 - accuracy: 1.0000\n",
      "Epoch 773/1000\n",
      "426/426 - 0s - loss: 1.3091e-06 - accuracy: 1.0000\n",
      "Epoch 774/1000\n",
      "426/426 - 0s - loss: 1.3085e-06 - accuracy: 1.0000\n",
      "Epoch 775/1000\n",
      "426/426 - 0s - loss: 1.2802e-06 - accuracy: 1.0000\n",
      "Epoch 776/1000\n",
      "426/426 - 0s - loss: 1.2668e-06 - accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "426/426 - 0s - loss: 1.2665e-06 - accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "426/426 - 0s - loss: 1.2654e-06 - accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "426/426 - 0s - loss: 1.2654e-06 - accuracy: 1.0000\n",
      "Epoch 780/1000\n",
      "426/426 - 0s - loss: 1.2654e-06 - accuracy: 1.0000\n",
      "Epoch 781/1000\n",
      "426/426 - 0s - loss: 1.2654e-06 - accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "426/426 - 0s - loss: 1.2553e-06 - accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "426/426 - 0s - loss: 1.2237e-06 - accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "426/426 - 0s - loss: 1.2234e-06 - accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "426/426 - 0s - loss: 1.2229e-06 - accuracy: 1.0000\n",
      "Epoch 786/1000\n",
      "426/426 - 0s - loss: 1.2229e-06 - accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "426/426 - 0s - loss: 1.2229e-06 - accuracy: 1.0000\n",
      "Epoch 788/1000\n",
      "426/426 - 0s - loss: 1.2223e-06 - accuracy: 1.0000\n",
      "Epoch 789/1000\n",
      "426/426 - 0s - loss: 1.1882e-06 - accuracy: 1.0000\n",
      "Epoch 790/1000\n",
      "426/426 - 0s - loss: 1.1333e-06 - accuracy: 1.0000\n",
      "Epoch 791/1000\n",
      "426/426 - 0s - loss: 1.1048e-06 - accuracy: 1.0000\n",
      "Epoch 792/1000\n",
      "426/426 - 0s - loss: 1.1045e-06 - accuracy: 1.0000\n",
      "Epoch 793/1000\n",
      "426/426 - 0s - loss: 1.1037e-06 - accuracy: 1.0000\n",
      "Epoch 794/1000\n",
      "426/426 - 0s - loss: 1.1034e-06 - accuracy: 1.0000\n",
      "Epoch 795/1000\n",
      "426/426 - 0s - loss: 1.1034e-06 - accuracy: 1.0000\n",
      "Epoch 796/1000\n",
      "426/426 - 0s - loss: 1.1031e-06 - accuracy: 1.0000\n",
      "Epoch 797/1000\n",
      "426/426 - 0s - loss: 1.1031e-06 - accuracy: 1.0000\n",
      "Epoch 798/1000\n",
      "426/426 - 0s - loss: 1.1031e-06 - accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "426/426 - 0s - loss: 1.0611e-06 - accuracy: 1.0000\n",
      "Epoch 800/1000\n",
      "426/426 - 0s - loss: 1.0611e-06 - accuracy: 1.0000\n",
      "Epoch 801/1000\n",
      "426/426 - 0s - loss: 1.0606e-06 - accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "426/426 - 0s - loss: 1.0606e-06 - accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "426/426 - 0s - loss: 1.0606e-06 - accuracy: 1.0000\n",
      "Epoch 804/1000\n",
      "426/426 - 0s - loss: 1.0600e-06 - accuracy: 1.0000\n",
      "Epoch 805/1000\n",
      "426/426 - 0s - loss: 1.0600e-06 - accuracy: 1.0000\n",
      "Epoch 806/1000\n",
      "426/426 - 0s - loss: 1.0600e-06 - accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "426/426 - 0s - loss: 1.0600e-06 - accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "426/426 - 0s - loss: 1.0192e-06 - accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "426/426 - 0s - loss: 1.0186e-06 - accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "426/426 - 0s - loss: 9.8557e-07 - accuracy: 1.0000\n",
      "Epoch 811/1000\n",
      "426/426 - 0s - loss: 9.4304e-07 - accuracy: 1.0000\n",
      "Epoch 812/1000\n",
      "426/426 - 0s - loss: 9.4192e-07 - accuracy: 1.0000\n",
      "Epoch 813/1000\n",
      "426/426 - 0s - loss: 9.4136e-07 - accuracy: 1.0000\n",
      "Epoch 814/1000\n",
      "426/426 - 0s - loss: 9.4108e-07 - accuracy: 1.0000\n",
      "Epoch 815/1000\n",
      "426/426 - 0s - loss: 9.4108e-07 - accuracy: 1.0000\n",
      "Epoch 816/1000\n",
      "426/426 - 0s - loss: 9.4080e-07 - accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "426/426 - 0s - loss: 9.3632e-07 - accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "426/426 - 0s - loss: 8.9911e-07 - accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "426/426 - 0s - loss: 8.9883e-07 - accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "426/426 - 0s - loss: 8.9827e-07 - accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "426/426 - 0s - loss: 8.9827e-07 - accuracy: 1.0000\n",
      "Epoch 822/1000\n",
      "426/426 - 0s - loss: 8.9799e-07 - accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "426/426 - 0s - loss: 8.9771e-07 - accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "426/426 - 0s - loss: 8.9771e-07 - accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "426/426 - 0s - loss: 8.9771e-07 - accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "426/426 - 0s - loss: 8.9771e-07 - accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "426/426 - 0s - loss: 8.9771e-07 - accuracy: 1.0000\n",
      "Epoch 828/1000\n",
      "426/426 - 0s - loss: 8.7196e-07 - accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "426/426 - 0s - loss: 8.5601e-07 - accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "426/426 - 0s - loss: 8.5545e-07 - accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "426/426 - 0s - loss: 8.5517e-07 - accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "426/426 - 0s - loss: 8.5517e-07 - accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "426/426 - 0s - loss: 8.5517e-07 - accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "426/426 - 0s - loss: 8.5517e-07 - accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "426/426 - 0s - loss: 8.4314e-07 - accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "426/426 - 0s - loss: 7.8130e-07 - accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "426/426 - 0s - loss: 7.7962e-07 - accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "426/426 - 0s - loss: 7.7850e-07 - accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "426/426 - 0s - loss: 7.7290e-07 - accuracy: 1.0000\n",
      "Epoch 840/1000\n",
      "426/426 - 0s - loss: 7.3680e-07 - accuracy: 1.0000\n",
      "Epoch 841/1000\n",
      "426/426 - 0s - loss: 7.3652e-07 - accuracy: 1.0000\n",
      "Epoch 842/1000\n",
      "426/426 - 0s - loss: 7.3596e-07 - accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "426/426 - 0s - loss: 7.3596e-07 - accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "426/426 - 0s - loss: 7.3568e-07 - accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "426/426 - 0s - loss: 7.3540e-07 - accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "426/426 - 0s - loss: 7.3540e-07 - accuracy: 1.0000\n",
      "Epoch 847/1000\n",
      "426/426 - 0s - loss: 7.3540e-07 - accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "426/426 - 0s - loss: 7.3540e-07 - accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "426/426 - 0s - loss: 7.3540e-07 - accuracy: 1.0000\n",
      "Epoch 850/1000\n",
      "426/426 - 0s - loss: 7.3540e-07 - accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "426/426 - 0s - loss: 7.3540e-07 - accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "426/426 - 0s - loss: 7.1246e-07 - accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "426/426 - 0s - loss: 6.9343e-07 - accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "426/426 - 0s - loss: 6.9315e-07 - accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "426/426 - 0s - loss: 6.9287e-07 - accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "426/426 - 0s - loss: 6.9287e-07 - accuracy: 1.0000\n",
      "Epoch 857/1000\n",
      "426/426 - 0s - loss: 6.9287e-07 - accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "426/426 - 0s - loss: 6.9287e-07 - accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "426/426 - 0s - loss: 6.9287e-07 - accuracy: 1.0000\n",
      "Epoch 860/1000\n",
      "426/426 - 0s - loss: 6.9287e-07 - accuracy: 1.0000\n",
      "Epoch 861/1000\n",
      "426/426 - 0s - loss: 6.9231e-07 - accuracy: 1.0000\n",
      "Epoch 862/1000\n",
      "426/426 - 0s - loss: 6.9231e-07 - accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "426/426 - 0s - loss: 6.9231e-07 - accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "426/426 - 0s - loss: 6.9231e-07 - accuracy: 1.0000\n",
      "Epoch 865/1000\n",
      "426/426 - 0s - loss: 6.9231e-07 - accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "426/426 - 0s - loss: 6.7356e-07 - accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "426/426 - 0s - loss: 6.1731e-07 - accuracy: 1.0000\n",
      "Epoch 868/1000\n",
      "426/426 - 0s - loss: 5.7702e-07 - accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "426/426 - 0s - loss: 5.7478e-07 - accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "426/426 - 0s - loss: 5.7394e-07 - accuracy: 1.0000\n",
      "Epoch 871/1000\n",
      "426/426 - 0s - loss: 5.7338e-07 - accuracy: 1.0000\n",
      "Epoch 872/1000\n",
      "426/426 - 0s - loss: 5.7338e-07 - accuracy: 1.0000\n",
      "Epoch 873/1000\n",
      "426/426 - 0s - loss: 5.7310e-07 - accuracy: 1.0000\n",
      "Epoch 874/1000\n",
      "426/426 - 0s - loss: 5.7310e-07 - accuracy: 1.0000\n",
      "Epoch 875/1000\n",
      "426/426 - 0s - loss: 5.7310e-07 - accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "426/426 - 0s - loss: 5.7310e-07 - accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "426/426 - 0s - loss: 5.7310e-07 - accuracy: 1.0000\n",
      "Epoch 878/1000\n",
      "426/426 - 0s - loss: 5.7310e-07 - accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "426/426 - 0s - loss: 5.7310e-07 - accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "426/426 - 0s - loss: 5.7282e-07 - accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "426/426 - 0s - loss: 5.7254e-07 - accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "426/426 - 0s - loss: 5.4624e-07 - accuracy: 1.0000\n",
      "Epoch 883/1000\n",
      "426/426 - 0s - loss: 5.3140e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 884/1000\n",
      "426/426 - 0s - loss: 5.3112e-07 - accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "426/426 - 0s - loss: 5.3057e-07 - accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "426/426 - 0s - loss: 5.3057e-07 - accuracy: 1.0000\n",
      "Epoch 887/1000\n",
      "426/426 - 0s - loss: 5.3057e-07 - accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "426/426 - 0s - loss: 5.3057e-07 - accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "426/426 - 0s - loss: 5.3057e-07 - accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "426/426 - 0s - loss: 5.3057e-07 - accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "426/426 - 0s - loss: 5.3001e-07 - accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "426/426 - 0s - loss: 5.3001e-07 - accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "426/426 - 0s - loss: 5.3001e-07 - accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "426/426 - 0s - loss: 5.3001e-07 - accuracy: 1.0000\n",
      "Epoch 895/1000\n",
      "426/426 - 0s - loss: 5.3001e-07 - accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "426/426 - 0s - loss: 5.3001e-07 - accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "426/426 - 0s - loss: 5.3001e-07 - accuracy: 1.0000\n",
      "Epoch 898/1000\n",
      "426/426 - 0s - loss: 5.3001e-07 - accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "426/426 - 0s - loss: 5.3001e-07 - accuracy: 1.0000\n",
      "Epoch 900/1000\n",
      "426/426 - 0s - loss: 5.1378e-07 - accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "426/426 - 0s - loss: 4.8887e-07 - accuracy: 1.0000\n",
      "Epoch 902/1000\n",
      "426/426 - 0s - loss: 4.8859e-07 - accuracy: 1.0000\n",
      "Epoch 903/1000\n",
      "426/426 - 0s - loss: 4.8747e-07 - accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "426/426 - 0s - loss: 4.8747e-07 - accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "426/426 - 0s - loss: 4.8747e-07 - accuracy: 1.0000\n",
      "Epoch 906/1000\n",
      "426/426 - 0s - loss: 4.8747e-07 - accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "426/426 - 0s - loss: 4.8747e-07 - accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "426/426 - 0s - loss: 4.8747e-07 - accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "426/426 - 0s - loss: 4.8747e-07 - accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "426/426 - 0s - loss: 4.2059e-07 - accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "426/426 - 0s - loss: 4.1276e-07 - accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "426/426 - 0s - loss: 4.1164e-07 - accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "426/426 - 0s - loss: 4.1136e-07 - accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "426/426 - 0s - loss: 4.1108e-07 - accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "426/426 - 0s - loss: 4.1108e-07 - accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "426/426 - 0s - loss: 4.1052e-07 - accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "426/426 - 0s - loss: 4.1024e-07 - accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "426/426 - 0s - loss: 4.1024e-07 - accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "426/426 - 0s - loss: 4.1024e-07 - accuracy: 1.0000\n",
      "Epoch 920/1000\n",
      "426/426 - 0s - loss: 4.1024e-07 - accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "426/426 - 0s - loss: 4.0940e-07 - accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "426/426 - 0s - loss: 3.6882e-07 - accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "426/426 - 0s - loss: 3.6882e-07 - accuracy: 1.0000\n",
      "Epoch 924/1000\n",
      "426/426 - 0s - loss: 3.6826e-07 - accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "426/426 - 0s - loss: 3.6826e-07 - accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "426/426 - 0s - loss: 3.6826e-07 - accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "426/426 - 0s - loss: 3.6826e-07 - accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "426/426 - 0s - loss: 3.6826e-07 - accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "426/426 - 0s - loss: 3.6826e-07 - accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "426/426 - 0s - loss: 3.6826e-07 - accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 938/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "426/426 - 0s - loss: 3.6770e-07 - accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "426/426 - 0s - loss: 3.4867e-07 - accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "426/426 - 0s - loss: 3.2573e-07 - accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "426/426 - 0s - loss: 3.2573e-07 - accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "426/426 - 0s - loss: 3.2545e-07 - accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 956/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 959/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 965/1000\n",
      "426/426 - 0s - loss: 3.2517e-07 - accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "426/426 - 0s - loss: 3.2461e-07 - accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "426/426 - 0s - loss: 3.2461e-07 - accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "426/426 - 0s - loss: 3.2461e-07 - accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "426/426 - 0s - loss: 3.2461e-07 - accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "426/426 - 0s - loss: 3.2461e-07 - accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "426/426 - 0s - loss: 3.2461e-07 - accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "426/426 - 0s - loss: 3.2461e-07 - accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "426/426 - 0s - loss: 3.2461e-07 - accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "426/426 - 0s - loss: 3.0166e-07 - accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "426/426 - 0s - loss: 2.5073e-07 - accuracy: 1.0000\n",
      "Epoch 976/1000\n",
      "426/426 - 0s - loss: 2.4961e-07 - accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "426/426 - 0s - loss: 2.4849e-07 - accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "426/426 - 0s - loss: 2.4821e-07 - accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "426/426 - 0s - loss: 2.3450e-07 - accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "426/426 - 0s - loss: 2.0708e-07 - accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "426/426 - 0s - loss: 2.0680e-07 - accuracy: 1.0000\n",
      "Epoch 982/1000\n",
      "426/426 - 0s - loss: 2.0596e-07 - accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "426/426 - 0s - loss: 2.0596e-07 - accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "426/426 - 0s - loss: 2.0596e-07 - accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "426/426 - 0s - loss: 2.0596e-07 - accuracy: 1.0000\n",
      "Epoch 986/1000\n",
      "426/426 - 0s - loss: 2.0596e-07 - accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "426/426 - 0s - loss: 2.0596e-07 - accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n",
      "Epoch 992/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n",
      "Epoch 994/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "426/426 - 0s - loss: 2.0540e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x274e99891c8>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=1000,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 - 0s - loss: 0.2645 - accuracy: 0.9650\n",
      "Loss: 0.26450412269535967, Accuracy: 0.9650349617004395\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the testing data\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
